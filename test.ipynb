{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import mlflow\n",
    "import mlflow.keras\n",
    "from sklearn.metrics import precision_score, recall_score, accuracy_score, f1_score, cohen_kappa_score\n",
    "from tensorflow import keras\n",
    "from keras.layers import Conv2D, MaxPooling2D, BatchNormalizationV2\n",
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def datagen():\n",
    "    train_datagen = ImageDataGenerator(\n",
    "          rescale=1./255,\n",
    "          shear_range=0.2,\n",
    "          zoom_range=0.2,\n",
    "          horizontal_flip=True)\n",
    "    test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "    return train_datagen, test_datagen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_set(train_datagen, test_datagen, train_path, test_path):\n",
    "    training_set = train_datagen.flow_from_directory(\n",
    "          train_path,\n",
    "          target_size=(64, 64),\n",
    "          batch_size=32,\n",
    "          class_mode='categorical')\n",
    "    test_set = test_datagen.flow_from_directory(\n",
    "          test_path,\n",
    "          target_size=(64, 64),\n",
    "          batch_size=32,\n",
    "          class_mode='categorical',\n",
    "          shuffle=False)  # Ensure the order of the test set remains the same\n",
    "    return training_set, test_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(weight_decay):\n",
    "    cnn = tf.keras.models.Sequential([\n",
    "        tf.keras.layers.Conv2D(filters=32, kernel_size=3, activation='relu', input_shape=[64, 64, 3],\n",
    "                               kernel_regularizer=tf.keras.regularizers.l2(weight_decay)),\n",
    "        tf.keras.layers.MaxPool2D(pool_size=2, strides=2),\n",
    "        tf.keras.layers.Conv2D(filters=32, kernel_size=3, activation='relu',\n",
    "                               kernel_regularizer=tf.keras.regularizers.l2(weight_decay)),\n",
    "        tf.keras.layers.BatchNormalization(),  # Add BatchNormalization here\n",
    "        tf.keras.layers.Conv2D(filters=32, kernel_size=3, activation='relu',\n",
    "                               kernel_regularizer=tf.keras.regularizers.l2(weight_decay)),\n",
    "        tf.keras.layers.MaxPool2D(pool_size=2, strides=2),\n",
    "        tf.keras.layers.Conv2D(filters=32, kernel_size=3, activation='relu',\n",
    "                               kernel_regularizer=tf.keras.regularizers.l2(weight_decay)),\n",
    "        tf.keras.layers.BatchNormalization(),  # Add BatchNormalization here\n",
    "        tf.keras.layers.Flatten(),\n",
    "        tf.keras.layers.Dense(units=128, activation='relu',\n",
    "                              kernel_regularizer=tf.keras.regularizers.l2(weight_decay)),\n",
    "        tf.keras.layers.Dense(4, activation='softmax')\n",
    "    ])\n",
    "    return cnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=10,\n",
    "    restore_best_weights=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------Starting---------------------------\n",
      "defined model, optimizer, and compilation done\n",
      "------------defined model, optimizer, and compilation done----------------------\n",
      "Found 2870 images belonging to 4 classes.\n",
      "Found 394 images belonging to 4 classes.\n",
      "----------------------------training begin---------------------------\n",
      "Epoch 1/10\n",
      "90/90 [==============================] - 94s 1s/step - loss: 1.4066 - accuracy: 0.4056 - val_loss: 1.4606 - val_accuracy: 0.1878\n",
      "Epoch 2/10\n",
      "90/90 [==============================] - 114s 1s/step - loss: 1.1763 - accuracy: 0.5028 - val_loss: 1.6107 - val_accuracy: 0.1878\n",
      "Epoch 3/10\n",
      "90/90 [==============================] - 101s 1s/step - loss: 1.0621 - accuracy: 0.5767 - val_loss: 1.7496 - val_accuracy: 0.1878\n",
      "Epoch 4/10\n",
      "90/90 [==============================] - 106s 1s/step - loss: 1.0038 - accuracy: 0.5993 - val_loss: 1.7464 - val_accuracy: 0.2259\n",
      "Epoch 5/10\n",
      "90/90 [==============================] - 133s 1s/step - loss: 0.9702 - accuracy: 0.6171 - val_loss: 1.6659 - val_accuracy: 0.3147\n",
      "Epoch 6/10\n",
      "90/90 [==============================] - 109s 1s/step - loss: 0.9041 - accuracy: 0.6376 - val_loss: 1.6766 - val_accuracy: 0.3604\n",
      "Epoch 7/10\n",
      "90/90 [==============================] - 88s 977ms/step - loss: 0.8831 - accuracy: 0.6463 - val_loss: 1.7618 - val_accuracy: 0.4137\n",
      "Epoch 8/10\n",
      "90/90 [==============================] - 28s 310ms/step - loss: 0.8567 - accuracy: 0.6516 - val_loss: 1.8537 - val_accuracy: 0.4416\n",
      "Epoch 9/10\n",
      "90/90 [==============================] - 79s 886ms/step - loss: 0.8367 - accuracy: 0.6669 - val_loss: 1.9210 - val_accuracy: 0.4416\n",
      "Epoch 10/10\n",
      "90/90 [==============================] - 97s 1s/step - loss: 0.8015 - accuracy: 0.6815 - val_loss: 2.0073 - val_accuracy: 0.4442\n",
      "13/13 [==============================] - 7s 376ms/step\n",
      "----------------------------training end---------------------------\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    print(\"---------------------------Starting---------------------------\")\n",
    "    weight_decay = 1e-4  # Weight decay factor\n",
    "    learning_rate = 1e-5  # Custom learning rate\n",
    "\n",
    "    cnn = model(weight_decay)\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "    cnn.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    print(\"defined model, optimizer, and compilation done\")\n",
    "    print(\"------------defined model, optimizer, and compilation done----------------------\")\n",
    "    train_path = 'dataset\\Training'\n",
    "    test_path = 'dataset/Testing'\n",
    "    train_datagen, test_datagen = datagen()\n",
    "\n",
    "    if not os.path.exists(train_path):\n",
    "        raise FileNotFoundError(f\"Training directory not found: {train_path}\")\n",
    "    if not os.path.exists(test_path):\n",
    "        raise FileNotFoundError(f\"Test directory not found: {test_path}\")\n",
    "    \n",
    "    training_set, test_set = train_test_set(train_datagen, test_datagen, train_path, test_path)\n",
    "    print(\"----------------------------training begin---------------------------\")\n",
    "\n",
    "    history = cnn.fit(x=training_set, validation_data=test_set, epochs=10, callbacks=[early_stopping])\n",
    "\n",
    "    # Get predictions\n",
    "    y_pred = np.argmax(cnn.predict(test_set), axis=1)\n",
    "    y_true = test_set.classes  # Directly use the classes attribute\n",
    "    print(\"----------------------------training end---------------------------\")\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
